{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samgregson/GHPT-colab-experiments/blob/main/Grasshopper_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS2KaXUa6ULz"
      },
      "source": [
        "# Setup\n",
        "install openai and setup API key\n",
        "\n",
        "This notebook works both in a Colab environment and on local machine\n",
        "\n",
        "Colab:\n",
        "- API key must be saved in Colab sectrets as OPENAI_API_KEY\n",
        "\n",
        "Local:\n",
        "- API key must be defined in the .env file (refer to example.env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "IN_COLAB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    %pip install openai\n",
        "    %pip install requests\n",
        "\n",
        "if IN_COLAB:\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "    os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "    os.environ[\"LANGCHAIN_PROJECT\"] = \"GHPT_Instructor\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### load files into Colab and install package\n",
        "\n",
        "NOTE: you may need to refresh your Colab files directory to see changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    # remove the existing directory\n",
        "    import shutil\n",
        "    shutil.rmtree('/content/GHPT-experiments/', ignore_errors=True)\n",
        "    %git clone \"https://github.com/samgregson/GHPT-experiments\"\n",
        "    %pip install -e /content/GHPT-experiments/\n",
        "    # add the modules to the search path\n",
        "    import site\n",
        "    site.main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the correct SSL certificates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\GRE111160\\AppData\\Roaming\\ssl\\ca-certificates.cer\n"
          ]
        }
      ],
      "source": [
        "if not IN_COLAB:\n",
        "    from dotenv import load_dotenv\n",
        "    import os\n",
        "    import ssl\n",
        "    load_dotenv()\n",
        "    context = ssl.create_default_context(cafile=os.environ.get(\"REQUESTS_CA_BUNDLE\"))\n",
        "    print(os.environ.get(\"REQUESTS_CA_BUNDLE\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "test SSL certificate, this should return `<Response [200]>` if not try restarting the Jupyter kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "requests.get(\"https://api.smith.langchain.com/docs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCORn5u76b3n"
      },
      "source": [
        "### OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_KuOYMzj61v3"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from langsmith.wrappers import wrap_openai\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# Custom wrap for VSCode, needs to be the first wrap!\n",
        "if not IN_COLAB:\n",
        "    from patch_openai.patch_openai import patch_openai\n",
        "    client = patch_openai(client)\n",
        "\n",
        "# Wrap the OpenAI client with LangSmith\n",
        "client = wrap_openai(client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47XPmW1mPiTw"
      },
      "source": [
        "# GHPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb2mp36c73Yi"
      },
      "source": [
        "### Import prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gKpcZiiP5rMX"
      },
      "outputs": [],
      "source": [
        "from prompts.generate_script import system_prompt, prompt_template\n",
        "\n",
        "# replace all { with {{ and } with }} to escape the curly braces\n",
        "prompt_template = prompt_template.replace(\"{\",\"{{\").replace(\"}\",\"}}\").replace(\"{{QUESTION}}\",\"{QUESTION}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnxRNbOBFhE7"
      },
      "source": [
        "# Instructor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NZrSSRF8O3sn"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !pip install -U instructor\n",
        "    !pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U60h0Nz7O1H7"
      },
      "outputs": [],
      "source": [
        "import instructor\n",
        "\n",
        "client_instructor = instructor.patch(client, mode=instructor.Mode.TOOLS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0ke-FfdlPkWk"
      },
      "outputs": [],
      "source": [
        "from langsmith import traceable\n",
        "from models.models import GrasshopperScriptModel\n",
        "\n",
        "# create the openai api call function\n",
        "@traceable\n",
        "def call_openai_instructor(prompt: str, system_prompt: str = \"\", model: str = \"gpt-3.5-turbo-1106\", temperature: float = 0):\n",
        "    completion = client_instructor.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        response_model=GrasshopperScriptModel,\n",
        "        max_retries = 2\n",
        "    )\n",
        "\n",
        "    return completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gfnp9bV_Pl0Z",
        "outputId": "43c9b714-85cd-4dea-d007-da68e1ee5db0"
      },
      "outputs": [],
      "source": [
        "model = \"gpt-3.5-turbo-1106\"\n",
        "# model = \"gpt-4-1106-preview\"\n",
        "response = call_openai_instructor(prompt='Create a cone with a base radius of 5 and a height of 10', system_prompt=system_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "lL4g-30zQY63",
        "outputId": "712dfcf6-182d-4196-8cec-259f612dd8ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"ChainOfThought\":\"Create a Point at the tip of the cone, Create a Circle at the base of the cone, Create a Cone using the Point and Circle as inputs\",\"Additions\":[{\"Name\":\"Point\",\"Id\":1},{\"Name\":\"Circle\",\"Id\":2},{\"Name\":\"Cone\",\"Id\":3},{\"Name\":\"Number Slider\",\"Id\":4},{\"Name\":\"Number Slider\",\"Id\":5}],\"Connections\":[{\"From\":{\"Id\":1,\"ParameterName\":\"Point\"},\"To\":{\"Id\":3,\"ParameterName\":\"Apex\"}},{\"From\":{\"Id\":2,\"ParameterName\":\"Circle\"},\"To\":{\"Id\":3,\"ParameterName\":\"Base\"}},{\"From\":{\"Id\":4,\"ParameterName\":\"Slider\"},\"To\":{\"Id\":2,\"ParameterName\":\"Radius\"}},{\"From\":{\"Id\":5,\"ParameterName\":\"Slider\"},\"To\":{\"Id\":3,\"ParameterName\":\"Height\"}}],\"Advice\":\"Adjust the Number Sliders to change the base radius and height of the cone.\"}\n"
          ]
        }
      ],
      "source": [
        "print(response.json())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMfW6HNeJ1iT+VDWPPQb17l",
      "collapsed_sections": [
        "KS2KaXUa6ULz"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
